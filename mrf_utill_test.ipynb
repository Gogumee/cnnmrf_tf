{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mrf_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# create_local_patches_sanity_check_1 \n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 1, 3, 3, 1\n",
    "    patch_size = 3\n",
    "    generated_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    local_patches = create_local_patches(generated_layer, patch_size)\n",
    "    \n",
    "    init_generated_layer = np.array([[[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]]])\n",
    "    \n",
    "    feed_dict = {generated_layer: init_generated_layer}\n",
    "    \n",
    "    expected_output = np.array([[[[1, 2, 3, 4, 5, 6, 7, 8, 9]]]])\n",
    "    print(np.all((local_patches.eval(feed_dict) - expected_output) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# create_local_patches_sanity_check_2\n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 1, 3, 3, 1\n",
    "    patch_size = 2\n",
    "    generated_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    local_patches = create_local_patches(generated_layer, patch_size)\n",
    "    \n",
    "    init_generated_layer = np.array([[[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]]])\n",
    "    \n",
    "    feed_dict = {generated_layer: init_generated_layer}\n",
    "    \n",
    "    expected_output = np.array([[[[1, 2, 4, 5], [2, 3, 5, 6]], [[4, 5, 7, 8], [5, 6, 8, 9]]]])\n",
    "    print(np.all((local_patches.eval(feed_dict) - expected_output) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 8)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# create_local_patches_sanity_check_3\n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 1, 3, 3, 2\n",
    "    patch_size = 2\n",
    "    generated_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    local_patches = create_local_patches(generated_layer, patch_size)\n",
    "    \n",
    "    init_generated_layer = np.array(\n",
    "                [[[[1, 1], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]]])    \n",
    "    feed_dict = {generated_layer: init_generated_layer}\n",
    "    \n",
    "    expected_output = np.array([[[[1, 1, 2, 2, 4, 4, 5, 5], [2, 2, 3, 3, 5, 5, 6, 6]],\n",
    "                                         [[4, 4, 5, 5, 7, 7, 8, 8], [5, 5, 6, 6, 8, 8, 9, 9]]]])\n",
    "    print(expected_output.shape)\n",
    "    print(np.all((local_patches.eval(feed_dict) - expected_output) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.  2.  4.  5.]\n",
      "   [ 2.  3.  5.  6.]]\n",
      "\n",
      "  [[ 4.  5.  7.  8.]\n",
      "   [ 5.  6.  8.  9.]]]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# patch_matching_sanity_check_1\n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 1, 3, 3, 1\n",
    "    patch_size = 2\n",
    "    generated_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    generated_layer_patches = create_local_patches(generated_layer, patch_size)\n",
    "\n",
    "    style_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    style_layer_patches = create_local_patches(style_layer, patch_size)\n",
    "\n",
    "    actual_output = patch_matching(generated_layer_patches, style_layer_patches, patch_size)\n",
    "\n",
    "    init_generated_layer = np.array([[[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]]])\n",
    "    feed_dict = {generated_layer: init_generated_layer, style_layer: init_generated_layer}\n",
    "    expected_output = np.array([[[[1, 2, 4, 5], [2, 3, 5, 6]], [[4, 5, 7, 8], [5, 6, 8, 9]]]])\n",
    "    print(actual_output.eval(feed_dict))\n",
    "    print(np.all((actual_output.eval(feed_dict) - expected_output) < 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[[ 1.  1.  2.  2.  4.  4.  5.  5.]\n",
      "   [ 2.  2.  3.  3.  5.  5.  6.  6.]]\n",
      "\n",
      "  [[ 4.  4.  5.  5.  7.  7.  8.  8.]\n",
      "   [ 5.  5.  6.  6.  8.  8.  9.  9.]]]\n",
      "\n",
      "\n",
      " [[[ 4.  4.  5.  5.  7.  7.  8.  8.]\n",
      "   [ 5.  5.  6.  6.  8.  8.  9.  9.]]\n",
      "\n",
      "  [[ 5.  5.  6.  6.  8.  8.  9.  9.]\n",
      "   [ 5.  5.  6.  6.  8.  8.  9.  9.]]]]\n",
      "(2, 2, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "# patch_matching_sanity_check_2\n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 2, 3, 3, 2\n",
    "    patch_size = 2\n",
    "    generated_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    generated_layer_patches = create_local_patches(generated_layer, patch_size)\n",
    "\n",
    "    style_layer = tf.placeholder(tf.float32, shape=(1, height, width, feature))\n",
    "    style_layer_patches = create_local_patches(style_layer, patch_size)\n",
    "\n",
    "#     normalized_style_layer_patches = tf.nn.l2_normalize(style_layer_patches, dim=[3])\n",
    "    actual_output = patch_matching(generated_layer_patches, style_layer_patches, patch_size)\n",
    "\n",
    "    init_generated_layer = np.array(\n",
    "    [[[[1, 1], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]],\n",
    "     [[[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]], [[7, 7], [8, 8], [9, 9]]]])\n",
    "    init_style_layer = np.array(\n",
    "        [[[[1, 1], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]]])\n",
    "    \n",
    "    feed_dict = {generated_layer: init_generated_layer, style_layer: init_style_layer}\n",
    "    expected_output = np.array([[[[1, 1, 2, 2, 4, 4, 5, 5], [2, 2, 3, 3, 5, 5, 6, 6]],\n",
    "                             [[4, 4, 5, 5, 7, 7, 8, 8], [5, 5, 6, 6, 8, 8, 9, 9]]],\n",
    "                            [[[4, 4, 5, 5, 7, 7, 8, 8], [5, 5, 6, 6, 8, 8, 9, 9]],\n",
    "                             [[5, 5, 6, 6, 8, 8, 9, 9], [5, 5, 6, 6, 8, 8, 9, 9]]]])\n",
    "#     expected_output = expected_output / np.expand_dims(np.linalg.norm(expected_output, axis=(3)), axis=3)\n",
    "    print(np.all((actual_output.eval(feed_dict) - expected_output) < 1e-3))\n",
    "    print(actual_output.eval(feed_dict))\n",
    "    print(actual_output.eval(feed_dict).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777778\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# mrf_loss => 나중에 프린트할때 배치 사이즈로 나눠주기\n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 2, 3, 3, 2\n",
    "    patch_size = 2\n",
    "    generated_layer = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    generated_layer_patches = create_local_patches(generated_layer, patch_size)\n",
    "\n",
    "    style_layer = tf.placeholder(tf.float32, shape=(1, height, width, feature))\n",
    "    style_layer_patches = create_local_patches(style_layer, patch_size)\n",
    "\n",
    "    normalized_style_layer_patches = tf.nn.l2_normalize(style_layer_patches, dim=[3])\n",
    "    output = mrf_loss(style_layer, generated_layer, patch_size=patch_size)\n",
    "\n",
    "    init_generated_layer = np.array(\n",
    "    [\n",
    "        [[[1, 1], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]],\n",
    "        [[[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]], [[7, 7], [8, 8], [9, 9]]]\n",
    "    ])\n",
    "    init_style_layer = np.array(\n",
    "        [[[[1, 1], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]]])\n",
    "    \n",
    "    feed_dict = {generated_layer: init_generated_layer, style_layer: init_style_layer}\n",
    "    expected_output = (2.0 ** 2 * 4   +   1.0 ** 2 * 4   +   3.0 ** 2 * 4) / patch_size ** 2 / height * width * feature\n",
    "    print(output.eval(feed_dict))\n",
    "    print(np.all((output.eval(feed_dict) - expected_output) < 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333\n"
     ]
    }
   ],
   "source": [
    "# study of loss [divide by what?]\n",
    "# answer is := height * width * dimension\n",
    "with tf.Session() as sess:\n",
    "    batch, height, width, feature = 1, 3, 3, 3\n",
    "    a = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    b = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    loss = tf.losses.mean_squared_error(a, b)\n",
    "\n",
    "#     init_a = np.array([[[[1, 1], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]]])\n",
    "#     init_b = np.array([[[[3, 2], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]]])\n",
    "    \n",
    "    init_a = np.array([[[[1, 1, 1], [2, 2, 1], [3, 3, 1]], [[4, 4, 1], [5, 5, 1], [6, 6, 1]], [[7, 7, 1], [8, 8, 1], [9, 9, 1]]]])\n",
    "    init_b = np.array([[[[4, 1, 1], [2, 2, 1], [3, 3, 1]], [[4, 4, 1], [5, 5, 1], [6, 6, 1]], [[7, 7, 1], [8, 8, 1], [9, 9, 1]]]])\n",
    "    \n",
    "    feed_dict = {a: init_a, b: init_b}\n",
    "    print(loss.eval(feed_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
